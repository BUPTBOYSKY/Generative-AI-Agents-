{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/zzc/anaconda3/envs/coding/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:17<00:00,  2.21s/it]\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_311397/1218666997.py:40: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n",
      "/tmp/ipykernel_311397/1218666997.py:43: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# --- 模型加载 ---\n",
    "model_path = \"/home/student/zzc/deepseek/DeepSeek-R1-Distill-Qwen-32B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# --- Pipeline 创建 ---\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# --- Embedding 模型 ---\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"/home/student/zzc/代码/GAI-agent-satellite-main/embedding\",\n",
    "    model_kwargs={'device': 'cuda:0'}\n",
    ")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_311397/2547646776.py:6: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb_Scenarios_Homogeneous.persist()\n"
     ]
    }
   ],
   "source": [
    "# --- 加载和处理知识库 ---\n",
    "loader_Scenarios_Homogeneous = TextLoader('./database/ref_Scenarios_Homogeneous.txt')\n",
    "documents_Scenarios_Homogeneous = loader_Scenarios_Homogeneous.load()\n",
    "texts_Scenarios_Homogeneous = text_splitter.split_documents(documents_Scenarios_Homogeneous) \n",
    "vectordb_Scenarios_Homogeneous = Chroma.from_documents(texts_Scenarios_Homogeneous, embeddings, persist_directory=\"database/Scenarios_Homogeneous_db\")\n",
    "vectordb_Scenarios_Homogeneous.persist()\n",
    "\n",
    "loader_Scenarios_Heterogeneous = TextLoader('./database/ref_Scenarios_Heterogeneous.txt')\n",
    "documents_Scenarios_Heterogeneous = loader_Scenarios_Heterogeneous.load()\n",
    "texts_Scenarios_Heterogeneous = text_splitter.split_documents(documents_Scenarios_Heterogeneous)\n",
    "vectordb_Scenarios_Heterogeneous = Chroma.from_documents(texts_Scenarios_Heterogeneous, embeddings, persist_directory=\"database/Scenarios_Heterogeneous_db\")\n",
    "vectordb_Scenarios_Heterogeneous.persist()\n",
    "\n",
    "loader_SDMA = TextLoader('./database/ref_SDMA.txt')\n",
    "documents_SDMA = loader_SDMA.load()\n",
    "texts_SDMA = text_splitter.split_documents(documents_SDMA) \n",
    "vectordb_SDMA = Chroma.from_documents(texts_SDMA, embeddings, persist_directory=\"database/SDMA_db\")\n",
    "vectordb_SDMA.persist()\n",
    "\n",
    "loader_RSMA = TextLoader('./database/ref_RSMA.txt')\n",
    "documents_RSMA = loader_RSMA.load()\n",
    "texts_RSMA = text_splitter.split_documents(documents_RSMA) \n",
    "vectordb_RSMA = Chroma.from_documents(texts_RSMA, embeddings, persist_directory=\"database/RSMA_db\")\n",
    "vectordb_RSMA.persist()\n",
    "\n",
    "loader_Channels_Fixed = TextLoader('./database/ref_Channels_Fixed.txt')\n",
    "documents_Channels_Fixed = loader_Channels_Fixed.load()\n",
    "texts_Channels_Fixed = text_splitter.split_documents(documents_Channels_Fixed)\n",
    "vectordb_Channels_Fixed = Chroma.from_documents(texts_Channels_Fixed, embeddings, persist_directory=\"database/Channels_Fixed_db\")\n",
    "vectordb_Channels_Fixed.persist()\n",
    "\n",
    "loader_Channels_TimeVarying = TextLoader('./database/ref_Channels_TimeVarying.txt')\n",
    "documents_Channels_TimeVarying = loader_Channels_TimeVarying.load()\n",
    "texts_Channels_TimeVarying = text_splitter.split_documents(documents_Channels_TimeVarying)\n",
    "vectordb_Channels_TimeVarying = Chroma.from_documents(texts_Channels_TimeVarying, embeddings, persist_directory=\"database/Channels_TimeVarying_db\")\n",
    "vectordb_Channels_TimeVarying.persist()\n",
    "\n",
    "\n",
    "loader_Optimization_SE = TextLoader('./database/ref_Optimization_SE.txt')\n",
    "documents_Optimization_SE = loader_Optimization_SE.load()\n",
    "texts_Optimization_SE = text_splitter.split_documents(documents_Optimization_SE)\n",
    "vectordb_Optimization_SE = Chroma.from_documents(texts_Optimization_SE, embeddings, persist_directory=\"database/Optimization_SE_db\")\n",
    "vectordb_Optimization_SE.persist()\n",
    "\n",
    "loader_Optimization_EE = TextLoader('./database/ref_Optimization_EE.txt')\n",
    "documents_Optimization_EE = loader_Optimization_EE.load()\n",
    "texts_Optimization_EE = text_splitter.split_documents(documents_Optimization_EE)\n",
    "vectordb_Optimization_EE = Chroma.from_documents(texts_Optimization_EE, embeddings, persist_directory=\"database/Optimization_EE_db\")\n",
    "vectordb_Optimization_EE.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 创建 Retriever ---\n",
    "retriever_Scenarios_Homogeneous = vectordb_Scenarios_Homogeneous.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_Scenarios_Heterogeneous = vectordb_Scenarios_Heterogeneous.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_SDMA = vectordb_SDMA.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_RSMA = vectordb_RSMA .as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_Channels_Fixed = vectordb_Channels_Fixed.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_Channels_TimeVarying = vectordb_Channels_TimeVarying.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_Optimization_SE = vectordb_Optimization_SE.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_Optimization_EE = vectordb_Optimization_EE.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_representations = {\n",
    "    \"Scenarios\": \"Knowledge encompassing diverse satellite network deployment scenarios, including variations in constellation types (e.g., GEO, LEO), application-specific mission objectives (e.g., communication, Earth observation, navigation, scientific), and architectural configurations (e.g., bent-pipe, regenerative payload, inter-satellite links, ground segment topologies).\",\n",
    "    \"Access Protocols\": \"Knowledge concerning various multiple access protocols employed in satellite communication systems, such as Space Division Multiple Access (SDMA) utilizing beamforming, Rate-Splitting Multiple Access (RSMA) for non-orthogonal transmission. Understanding the operational principles, performance trade-offs, and application suitability of each protocol is crucial.\",\n",
    "    \"Channel Models\": \"Knowledge of different channel models relevant to satellite communication links, covering both static and dynamic channel conditions. This includes fixed channel models like Additive White Gaussian Noise (AWGN) for idealized scenarios and time-varying channel models to represent realistic impairments such as fading (e.g., Rician, Rayleigh, Nakagami-m), shadowing due to obstacles, atmospheric absorption, scintillation effects, rain attenuation, and Doppler frequency shifts caused by satellite motion. Understanding the statistical properties and parameters of these models is essential for link budget analysis and system design.\",\n",
    "    \"Optimization Goals\": \"Knowledge regarding various performance optimization objectives in satellite communication system design and operation. This includes maximizing Spectral Efficiency (SE) to improve data rates, enhancing Energy Efficiency (EE) to reduce power consumption, increasing system throughput for higher capacity, minimizing communication latency for real-time applications, ensuring fairness in resource allocation among multiple users, and guaranteeing Quality of Service (QoS) requirements for different service types.  Understanding the mathematical formulations of these objectives and the trade-offs between them is important for algorithm development and resource management.\"\n",
    "}\n",
    "\n",
    "sub_block_representations = {\n",
    "    \"Scenarios\": {\n",
    "        \"Homogeneous\": \"Homogeneous satellite network scenarios define constellations where all satellites possess uniform characteristics, including orbital altitude, coverage area, capabilities, and service provision. These scenarios are used for deploying and managing uniform constellations for specific applications, such as global broadband internet access via Low Earth Orbit (LEO) constellations, where consistency in service and design is crucial.\",\n",
    "        \"Heterogeneous\": \"Heterogeneous satellite network scenarios define constellations composed of satellites with diverse characteristics, including mixed orbital regimes (LEO, MEO, GEO), varied payloads (communication, Earth observation), and multi-layer network architectures. These scenarios are used to achieve enhanced coverage, capacity, and service diversity by integrating different satellite types, addressing complex application requirements like multi-service platforms and integrated Earth observation and communication systems.\"\n",
    "    },\n",
    "    \"Access Protocols\": {\n",
    "        \"SDMA\": \"Space Division Multiple Access (SDMA) protocol spatially separates users via beamforming techniques, including fixed, steerable, and adaptive beams, to enhance frequency reuse and system capacity in satellite networks. It's used to manage interference and improve efficiency by directing signals to specific user locations.\",\n",
    "        \"RSMA\": \"Rate-Splitting Multiple Access (RSMA) protocol improves spectral efficiency through non-orthogonal transmission, splitting user messages into common and private streams. Utilizing schemes like basic and enhanced RSMA, and employing successive interference cancellation (SIC) at receivers, it handles heterogeneous user demands and improves system throughput compared to orthogonal access methods in satellite communications.\"\n",
    "    },\n",
    "    \"Channel Models\": {\n",
    "        \"Fixed\": \"Fixed channel models, like the AWGN model, assume constant or slowly varying channel parameters (signal attenuation, noise power spectral density). These idealizations are used for initial link budget calculations, assessing performance under ideal conditions, and in static scenarios (fixed ground station to geostationary satellite), calculating path loss and antenna gain. They provide baselines for system design and are widely used in education.\",\n",
    "        \"Time-Varying\": \"Time-varying channel models account for channel parameter variations over time, accurately representing actual satellite communication. These models, like Rayleigh (NLOS), Rician (LOS with multipath), shadowing (obstruction-induced signal loss), and those describing Doppler shift, are used for simulating dynamic scenarios (mobile and LEO satellite communication), optimizing link performance in complex environments, designing anti-fading techniques, and developing Doppler compensation technologies.\"\n",
    "    },\n",
    "   \"Optimization Goals\": {\n",
    "        \"SE\": \"Spectral Efficiency (SE) optimization in satellite communications focuses on maximizing data rate per unit bandwidth through techniques like advanced modulation and coding, signal processing, interference management, and resource allocation. It's used to enhance data throughput in limited bandwidth scenarios, improving overall link and network capacity.\",\n",
    "        \"EE\": \"Energy Efficiency (EE) optimization in satellite communications aims to minimize power consumption while maintaining performance, employing methods such as power amplifier optimization, power control, energy-aware resource management, and efficient hardware design. It's crucial for extending the operational life of battery-powered terminals and payloads, especially in long-duration satellite missions.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_representation_embeddings = {\n",
    "    block_name: embeddings.embed_query(representation)\n",
    "    for block_name, representation in block_representations.items()\n",
    "}\n",
    "\n",
    "sub_block_representation_embeddings = {}\n",
    "for block_name, sub_blocks in sub_block_representations.items():\n",
    "    sub_block_representation_embeddings[block_name] = {\n",
    "        sub_block_name: embeddings.embed_query(representation)\n",
    "        for sub_block_name, representation in sub_blocks.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_to_block(query_embedding, block_representation_embeddings):\n",
    "    similarity_scores = {\n",
    "        block_name: torch.nn.functional.cosine_similarity(\n",
    "            torch.tensor(query_embedding),\n",
    "            torch.tensor(block_embedding),\n",
    "            dim=0\n",
    "        ).item()\n",
    "        for block_name, block_embedding in block_representation_embeddings.items()\n",
    "    }\n",
    "    selected_block = max(similarity_scores, key=similarity_scores.get)\n",
    "    print(f\"Layer-1 Routing: Selected Block - {selected_block}\")\n",
    "    return selected_block\n",
    "\n",
    "def route_to_sub_block(query_embedding, sub_block_representation_embeddings, selected_block):\n",
    "    similarity_scores = {\n",
    "        sub_block_name: torch.nn.functional.cosine_similarity(\n",
    "            torch.tensor(query_embedding),\n",
    "            torch.tensor(sub_block_embedding),\n",
    "            dim=0\n",
    "        ).item()\n",
    "        for sub_block_name, sub_block_embedding in sub_block_representation_embeddings[selected_block].items()\n",
    "    }\n",
    "    selected_sub_block = max(similarity_scores, key=similarity_scores.get)\n",
    "    print(f\"Layer-2 Routing: Selected Sub-block - {selected_sub_block} within {selected_block}\")\n",
    "    return selected_sub_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_history(history, pipe):\n",
    "    \"\"\"\n",
    "    总结对话历史。\n",
    "\n",
    "    Args:\n",
    "        history (list): 完整的对话历史列表，包含 HumanMessage 和 AIMessage 对象。\n",
    "        pipe:  HuggingFace Pipeline 对象，用于调用 DeepSeek 模型。\n",
    "\n",
    "    Returns:\n",
    "        str: 精炼后的对话历史摘要。\n",
    "    \"\"\"\n",
    "    if not history:\n",
    "        return \"\"\n",
    "\n",
    "    history_text = \"\"\n",
    "    for message in history:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            history_text += f\"User: {message.content}\\n\"\n",
    "        elif isinstance(message, AIMessage):\n",
    "            history_text += f\"Assistant: {message.content}\\n\"\n",
    "\n",
    "    summarization_prompt = f\"\"\"Please summarize the following conversation history, extract key information, and use concise language to summarize the main content of the conversation, so that subsequent conversations can quickly review the context. The final answer should start with \"Summary:\"\n",
    "\n",
    "    Dialogue history:\n",
    "    {history_text}\n",
    "\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "\n",
    "    summarized_text = pipe(summarization_prompt)[0]['generated_text']\n",
    "    think_tag_end = summarized_text.rfind(\"</think\")\n",
    "    \n",
    "    if think_tag_end != -1:\n",
    "        response_content_processed = summarized_text[think_tag_end + len(\"</think>\"):] # Extract after </think>\n",
    "        result_tag_end = response_content_processed.rfind(\"<Summary:>\")\n",
    "        if result_tag_end != -1:\n",
    "            response_content_processed = response_content_processed[result_tag_end + len(\"<Summary:>\"):]\n",
    "        else:\n",
    "            response_content_processed = response_content_processed\n",
    "    else:\n",
    "        response_content_processed = summarized_text # If </think> not found, return full response\n",
    "        \n",
    "    return response_content_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_deepseek(user_input, history, summarized_history_memory):\n",
    "    # 1. 编码用户查询\n",
    "    query_embedding = embeddings.embed_query(user_input)\n",
    "\n",
    "    # 2. Layer-1 路由 (选择 Block)\n",
    "    selected_block = route_to_block(query_embedding, block_representation_embeddings)\n",
    "\n",
    "    # 3. Layer-2 路由 (选择 Sub-block)\n",
    "    selected_sub_block = route_to_sub_block(query_embedding, sub_block_representation_embeddings, selected_block)\n",
    "\n",
    "    # 4. 基于路由结果选择 Retriever\n",
    "    retriever = None\n",
    "    if selected_block == \"Scenarios\":\n",
    "        if selected_sub_block == \"Homogeneous\":\n",
    "            retriever = retriever_Scenarios_Homogeneous\n",
    "        elif selected_sub_block == \"Heterogeneous\":\n",
    "            retriever = retriever_Scenarios_Heterogeneous\n",
    "    elif selected_block == \"Access Protocols\":\n",
    "        if selected_sub_block == \"SDMA\":\n",
    "            retriever = retriever_SDMA\n",
    "        elif selected_sub_block == \"RSMA\":\n",
    "            retriever = retriever_RSMA\n",
    "    elif selected_block == \"Channel Models\":\n",
    "        if selected_sub_block == \"Fixed\":\n",
    "            retriever = retriever_Channels_Fixed\n",
    "        elif selected_sub_block == \"Time-Varying\":\n",
    "            retriever = retriever_Channels_TimeVarying\n",
    "    elif selected_block == \"Optimization Goals\":\n",
    "        if selected_sub_block == \"SE\":\n",
    "            retriever = retriever_Optimization_SE\n",
    "        elif selected_sub_block == \"EE\":\n",
    "            retriever = retriever_Optimization_EE\n",
    "\n",
    "    if retriever is None:\n",
    "        retriever = retriever_SDMA\n",
    "\n",
    "    retrieved_chunks = retriever.get_relevant_documents(user_input)\n",
    "    context = \"\\n\\n\".join([chunk.page_content for chunk in retrieved_chunks])\n",
    "    \n",
    "    # Modified Prompt\n",
    "    prompt_content = f\"\"\"You are an expert in satellite communications. Please help me formulate a satellite communication model in English based on the following background knowledge and your local knowledge, maybe the background knowledge is wrong, so it just a reference. You just need to give a brief answer. If there are formulas, please also provide the corresponding modeled formulas. The final answer should start with \"Answer:\" \n",
    "    Summarized Conversation History:\n",
    "    {summarized_history_memory}\n",
    "    Background Knowledge:\n",
    "    {context}\n",
    "    Conversation History:\n",
    "    \"\"\"\n",
    "    for message in history: # 遍历对话历史\n",
    "        if isinstance(message, HumanMessage):\n",
    "            prompt_content += f\"User: {message.content}\\n\"\n",
    "        elif isinstance(message, AIMessage):\n",
    "            prompt_content += f\"Assistant: {message.content}\\n\"\n",
    "    prompt_content += f\"\"\"\n",
    "    User Problem:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "    generated_text = pipe(prompt_content)[0]['generated_text']\n",
    "    response_content = generated_text\n",
    "\n",
    "    # Extract content after </think> tag\n",
    "    think_tag_end = response_content.rfind(\"</think>\") # Use rfind to find the last </think>\n",
    "    if think_tag_end != -1:\n",
    "        response_content_processed = response_content[think_tag_end + len(\"</think>\"):] # Extract after </think>\n",
    "        result_tag_end = response_content_processed.rfind(\"<Answer:>\") # Use rfind to find the last <Answer:> in processed content\n",
    "        if result_tag_end != -1:\n",
    "            response_content_processed = response_content_processed[result_tag_end + len(\"<Answer:>\"):]\n",
    "        else:\n",
    "            response_content_processed = response_content_processed\n",
    "    else:\n",
    "        response_content_processed = response_content # If </think> not found, return full response\n",
    "\n",
    "    history.append(HumanMessage(content=user_input))\n",
    "    history.append(AIMessage(content=response_content_processed))\n",
    "\n",
    "    # 生成新的摘要\n",
    "    summarized_history_memory = summarize_history(history, pipe)\n",
    "\n",
    "    return response_content_processed, selected_block, selected_sub_block, summarized_history_memory # 返回处理后的生成结果和路由结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer-1 Routing: Selected Block - Access Protocols\n",
      "Layer-2 Routing: Selected Sub-block - SDMA within Access Protocols\n",
      "AI Assistant: \n",
      "\n",
      "Answer: \n",
      "\n",
      "In a satellite communication model utilizing SDMA at a LEO satellite, the transmit signals from a GEO satellite can be modeled as follows:\n",
      "\n",
      "**Transmit Signal Model:**\n",
      "\n",
      "For each user \\( k \\), the signal transmitted by the GEO satellite is denoted as \\( s_k \\).\n",
      "\n",
      "**Received Signal Model:**\n",
      "\n",
      "At the LEO satellite, the received signal \\( \\mathbf{y} \\) is given by:\n",
      "\n",
      "\\[\n",
      "\\mathbf{y} = \\sum_{k=1}^{N} \\mathbf{h}_k s_k + \\mathbf{n}\n",
      "\\]\n",
      "\n",
      "Where:\n",
      "- \\( N \\) is the total number of users/signals.\n",
      "- \\( \\mathbf{h}_k \\) is the channel vector representing the state of the channel for user \\( k \\).\n",
      "- \\( \\mathbf{n} \\) is the additive Gaussian noise accounting for thermal noise.\n",
      "\n",
      "**SINR Calculation:**\n",
      "\n",
      "The SINR for each user \\( k \\) is calculated as:\n",
      "\n",
      "\\[\n",
      "\\text{SINR}_k = \\frac{|\\mathbf{h}_k|^2 P}{\\sigma^2 + \\sum_{j \\neq k} |\\mathbf{h}_j|^2 P}\n",
      "\\]\n",
      "\n",
      "Where:\n",
      "- \\( P \\) is the transmit power per user.\n",
      "- \\( \\sigma^2 \\) is the noise variance.\n",
      "\n",
      "This model enables efficient resource allocation and interference management, ensuring scalable communication in a heterogeneous satellite network.\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "summarized_history_memory = \"\" \n",
    "user_input = \"Since heterogeneous satellite networks are considered, to ensure scalability, please use the SDMA protocol at the LEO satellite. Show the transmit signals generated by the GEO satellite. Answer based on your local knowledge.\"\n",
    "response, block1, sub_block1, summarized_history_memory = ask_deepseek(user_input, history, summarized_history_memory)\n",
    "print(f\"AI Assistant: {response}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Summary: The conversation discusses satellite communication models employing SDMA at LEO satellites. It covers the transmit signal model from GEO satellites, the received signal model including channel vectors and noise, and SINR calculations for each user, supporting scalable communication in a heterogeneous network.\n"
     ]
    }
   ],
   "source": [
    "print(summarized_history_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer-1 Routing: Selected Block - Channel Models\n",
      "Layer-2 Routing: Selected Sub-block - Fixed within Channel Models\n",
      "AI Assistant: \n",
      "\n",
      "Answer: \n",
      "\n",
      "The channel model for the satellite communication system using SDMA at LEO satellites can be described as follows:\n",
      "\n",
      "**Channel Model:**\n",
      "\n",
      "Each user's signal undergoes fading and attenuation through the satellite channel. The channel vector \\( \\mathbf{h}_k \\) for user \\( k \\) is composed of both line-of-sight (LOS) and non-line-of-sight (NLOS) components, represented as:\n",
      "\n",
      "\\[\n",
      "\\mathbf{h}_k = \\sqrt{\\alpha} \\mathbf{g}_{\\text{LOS},k} + \\sqrt{1-\\alpha} \\mathbf{g}_{\\text{NLOS},k}\n",
      "\\]\n",
      "\n",
      "Where:\n",
      "- \\( \\alpha \\) is the LOS probability.\n",
      "- \\( \\mathbf{g}_{\\text{LOS},k} \\) and \\( \\mathbf{g}_{\\text{NLOS},k} \\) are the respective channel gains for LOS and NLOS paths.\n",
      "\n",
      "**Power Delay Profile:**\n",
      "\n",
      "The channel's temporal characteristics are captured by the power delay profile (PDP), which for user \\( k \\) is:\n",
      "\n",
      "\\[\n",
      "f_k(\\tau) = \\beta_0 \\delta(\\tau) + \\sum_{l=1}^{L} \\beta_l e^{-\\gamma_l \\tau} \\cos(2\\pi f_d \\tau)\n",
      "\\]\n",
      "\n",
      "Where:\n",
      "- \\( \\beta_0 \\) is the direct path coefficient.\n",
      "- \\( \\beta_l \\) represents the multipath coefficients.\n",
      "- \\( \\gamma_l \\) is the exponential decay factor.\n",
      "- \\( f_d \\) is the Doppler frequency shift due to satellite movement.\n",
      "\n",
      "This channel model accounts for both spatial and temporal variations, essential for accurate performance evaluation in SDMA-based satellite systems.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Good, show me the corresponding channel model. Use your local knowledge.\" # Example user input, modify as needed\n",
    "response, block1, sub_block1, summarized_history_memory = ask_deepseek(user_input, history, summarized_history_memory)\n",
    "print(f\"AI Assistant: {response}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
